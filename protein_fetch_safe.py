"""
protein_fetch_safe.py
---------------------
ì¢… + ìœ ì „ìëª…ìœ¼ë¡œ NCBIì—ì„œ ë‹¨ë°±ì§ˆ FASTAë¥¼ ìë™ ìˆ˜ì§‘í•˜ì—¬ í•˜ë‚˜ì˜ ë©€í‹°-FASTA(.txt)ë¡œ ì €ì¥.

ê¸°ëŠ¥ ìš”ì•½
- NCBI ê²€ìƒ‰(db="protein") â†’ ì²« ë²ˆì§¸ ê²°ê³¼ë¥¼ efetchë¡œ ë°›ì•„ FASTA ì €ì¥
- ì˜¤ë¥˜/ê°„í—ì  ì‹¤íŒ¨ ëŒ€ë¹„ ì¬ì‹œë„
- ìš”ì²­ ê°„ê²©(ê¸°ë³¸ 0.5s) ì œí•œ
- ì…ë ¥: (1) íŒŒì´ì¬ ì¸ì species, genes / (2) í…ìŠ¤íŠ¸ íŒŒì¼(í•œ ì¤„ë‹¹ 'species<TAB>gene' ë˜ëŠ” 'species'ë§Œ)
- ì¶œë ¥: ì¶œë ¥ í´ë”ì— ê°œë³„ FASTA + ë³‘í•©ëœ multi_fasta.txt ìƒì„±
- Biopython í•„ìš”: pip install biopython

ì‚¬ìš© ì˜ˆì‹œ
----------
from protein_fetch_safe import fetch_from_txt, fetch_many

# 1) TXTë¡œ ì…ë ¥
fetch_from_txt("pairs.txt", out_dir="protein_results", email="you@example.com")

# 2) ì½”ë“œë¡œ ì§ì ‘ ì…ë ¥
species = ["Ursus maritimus", "Panthera tigris"]
genes   = ["LEP", "UCP1", "COX1"]
fetch_many(species, genes, out_dir="protein_results", email="you@example.com")
"""

from __future__ import annotations
from typing import List, Tuple, Optional
import os, time, sys, traceback
from Bio import Entrez, SeqIO
from collections import defaultdict

DEFAULT_DELAY = 0.5  # ìš”ì²­ ê°„ê²©(ì´ˆ)

def _ensure_email(email: Optional[str]):
    if not email or "@" not in email:
        raise ValueError("Entrez.emailì´ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ìœ íš¨í•œ ì´ë©”ì¼ì„ ì…ë ¥í•˜ì„¸ìš”.")
    Entrez.email = email

def entrez_search_id(query: str, db: str="protein", retmax: int=10, retries: int=3, delay: float=2.0) -> List[str]:
    for attempt in range(retries):
        try:
            with Entrez.esearch(db=db, term=query, retmax=retmax) as handle:
                rec = Entrez.read(handle)
            return rec.get("IdList", [])
        except Exception as e:
            print(f"âš ï¸ [ê²€ìƒ‰ ì‹¤íŒ¨ {attempt+1}/{retries}] {query} â†’ {e}")
            time.sleep(delay)
    print(f"âŒ ê²€ìƒ‰ ì™„ì „ ì‹¤íŒ¨: {query}")
    return []

def entrez_fetch_protein_fasta(ncbi_id: str, retries: int=3, delay: float=2.0):
    for attempt in range(retries):
        try:
            with Entrez.efetch(db="protein", id=ncbi_id, rettype="fasta", retmode="text") as handle:
                seq_record = SeqIO.read(handle, "fasta")
            return seq_record
        except Exception as e:
            print(f"âš ï¸ [ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨ {attempt+1}/{retries}] ID={ncbi_id} â†’ {e}")
            time.sleep(delay)
    print(f"âŒ ë‹¤ìš´ë¡œë“œ ì™„ì „ ì‹¤íŒ¨: {ncbi_id}")
    return None

def _sanitize_filename(s: str) -> str:
    return "".join(ch for ch in s.replace(" ", "_") if ch.isalnum() or ch in "._-")

def fetch_one(species: str, gene: str, out_dir: str, delay: float=DEFAULT_DELAY) -> Tuple[bool, Optional[str]]:
    os.makedirs(out_dir, exist_ok=True)
    query = f"{gene}[gene] AND {species}[organism]"
    ids = entrez_search_id(query)
    if not ids:
        print(f"ğŸš« {species} ({gene}) ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ")
        return False, None
    rec = entrez_fetch_protein_fasta(ids[0])
    if rec is None:
        print(f"ğŸš« {species} ({gene}) ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨")
        return False, None
    filename = f"{_sanitize_filename(species)}_{_sanitize_filename(gene)}.fasta"
    path = os.path.join(out_dir, filename)
    SeqIO.write(rec, path, "fasta")
    print(f"âœ… ì €ì¥ ì™„ë£Œ: {path}")
    time.sleep(delay)
    return True, path

def _unique(seq: List[str]) -> List[str]:
    seen = set(); out = []
    for x in seq:
        if x not in seen:
            seen.add(x); out.append(x)
    return out

def fetch_many(species_list: List[str], genes: List[str], out_dir: str, email: str,
               combine_filename: str="multi_fasta.txt", delay: float=DEFAULT_DELAY) -> str:
    """
    species_listì˜ ê° ì¢…ì— ëŒ€í•´ genes ëª©ë¡ì˜ ì²« ë²ˆì§¸ íˆíŠ¸ FASTAë¥¼ ë°›ì•„ ê°œë³„ íŒŒì¼ë¡œ ì €ì¥í•˜ê³ ,
    ì„±ê³µí•œ ê²ƒë“¤ì„ í•˜ë‚˜ì˜ ë©€í‹°-FASTA í…ìŠ¤íŠ¸(combine_filename)ë¡œ ë³‘í•©í•˜ì—¬ ë°˜í™˜.
    """
    _ensure_email(email)
    os.makedirs(out_dir, exist_ok=True)
    success_paths: List[str] = []
    species_list = [s.strip() for s in species_list if s and s.strip()]
    genes = _unique([g.strip() for g in genes if g and g.strip()])
    for sp in species_list:
        for g in genes:
            ok, p = fetch_one(sp, g, out_dir=out_dir, delay=delay)
            if ok and p:
                success_paths.append(p)

    grouped = defaultdict(list)
    for fp in success_paths:
        # íŒŒì¼ëª…ì—ì„œ ìœ ì „ì ì¶”ì¶œ (â€¦_CO1.fasta)
        gene = os.path.splitext(os.path.basename(fp))[0].split("_")[-1]
        grouped[gene].append(fp)

    for gene, paths in grouped.items():
        if len(paths) < 2:
            print(f"âš ï¸ {gene}: ì„œì—´ì´ {len(paths)}ê°œë¼ Gblocksìš© ë³‘í•©ì„ ê±´ë„ˆëœë‹ˆë‹¤.")
            continue
        combined = os.path.join(out_dir, f"multi_fasta_{gene}.txt")
        with open(combined, "w", encoding="utf-8") as out:
            for fp in paths:
                base = os.path.basename(fp)
                prefix = os.path.splitext(base)[0]  # Ursus_maritimus_CO1
                with open(fp, "r", encoding="utf-8") as f:
                    lines = f.readlines()
                # í—¤ë”ì— 'ì¢…_ìœ ì „ì ' ì ‘ë‘ì–´ ì¶”ê°€
                for i, line in enumerate(lines):
                    if line.startswith(">"):
                        lines[i] = f">{prefix} " + line[1:]
                        break
                out.write("".join(lines).rstrip() + "\n")
        print(f"ğŸ“¦ ë³‘í•© ì €ì¥: {combined} (entries: {len(paths)})")
    return combined

def fetch_from_txt(txt_path: str, out_dir: str, email: str,
                   combine_filename: str="multi_fasta.txt", delay: float=DEFAULT_DELAY) -> str:
    """
    txt í¬ë§·:
      - 'species<TAB>gene' í˜•ì‹ ë˜ëŠ”
      - 'species' ë‹¨ë… ë¼ì¸ë“¤ + í•¨ìˆ˜ ì¸ìë¡œ genes ì§€ì • ì‹œ ì‚¬ìš©

    ë°˜í™˜: ë³‘í•©ëœ multi_fasta.txt ê²½ë¡œ
    """
    _ensure_email(email)
    os.makedirs(out_dir, exist_ok=True)

    pairs: List[Tuple[str,str]] = []
    only_species: List[str] = []

    with open(txt_path, "r", encoding="utf-8") as f:
        for raw in f:
            s = raw.strip()
            if not s or s.startswith("#"):
                continue
            if "\t" in s:
                sp, ge = s.split("\t", 1)
                sp = sp.strip(); ge = ge.strip()
                if sp and ge:
                    pairs.append((sp, ge))
            else:
                only_species.append(s)

    success_paths: List[str] = []
    for sp, ge in pairs:
        ok, p = fetch_one(sp, ge, out_dir=out_dir, delay=delay)
        if ok and p:
            success_paths.append(p)

    combined = os.path.join(out_dir, combine_filename)
    with open(combined, "w", encoding="utf-8") as out:
        for fp in success_paths:
            with open(fp, "r", encoding="utf-8") as f:
                out.write(f.read().rstrip() + "\n")
    print(f"ğŸ“¦ ë³‘í•© ì €ì¥: {combined}  (entries: {len(success_paths)})")

    if only_species:
        print(f"â„¹ï¸ ì¢…ë§Œ ìˆëŠ” ë¼ì¸ {len(only_species)}ê°œ ë°œê²¬. ë³„ë„ genes ì¸ìì™€ í•¨ê»˜ fetch_many() í˜¸ì¶œì„ ê³ ë ¤í•˜ì„¸ìš”.")

    return combined

if __name__ == "__main__":
    # ê°„ë‹¨í•œ CLI
    import argparse
    ap = argparse.ArgumentParser()
    ap.add_argument("--email", required=True, help="Entrez.email (í•„ìˆ˜)")
    ap.add_argument("--txt", help="ì…ë ¥ TXT (species[\\tgene])")
    ap.add_argument("--out_dir", default="protein_results")
    ap.add_argument("--genes", help="ì½¤ë§ˆë¡œ êµ¬ë¶„ëœ ìœ ì „ì ëª©ë¡ (TXTê°€ species-onlyì¼ ë•Œ ì‚¬ìš©)")
    args = ap.parse_args()

    if args.txt:
        combined = fetch_from_txt(args.txt, args.out_dir, args.email)
    else:
        print("TXTê°€ ì—†ìœ¼ë©´ --genes ì™€ ì¢… ëª©ë¡(ì½”ë“œ ìˆ˜ì •)ì´ í•„ìš”í•©ë‹ˆë‹¤.")
        sys.exit(0)
